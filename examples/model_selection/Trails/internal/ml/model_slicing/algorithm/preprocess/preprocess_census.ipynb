{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangdan/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/huangdan/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Feb 08 10:42:13 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.8.3296). Expected < 9.8.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Feb 08 10:42:13 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.8.3296). Expected < 9.8.0. Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from optbinning import OptimalBinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/hdd1/sams/census/census.arff\"\n",
    "with open(file_path, 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False\n",
    "rows = []\n",
    "for line in lines:\n",
    "    if line.strip() == \"@data\":\n",
    "        flag = True\n",
    "        continue\n",
    "    \n",
    "    if not flag:\n",
    "        continue\n",
    "    \n",
    "    row = [i for i in line.strip().split(',')]\n",
    "    if len(row) != 42:\n",
    "        print(row)\n",
    "        break\n",
    "    rows.append(row) \n",
    "del lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = [0,2,3,5,16,17,18,24,30,36,38,39,40]\n",
    "len(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#col: 42\n",
      "0:91\n",
      "2:52\n",
      "3:47\n",
      "5:1425\n",
      "16:133\n",
      "17:114\n",
      "18:1675\n",
      "24:123232\n",
      "39:53\n"
     ]
    }
   ],
   "source": [
    "bin_cols = []\n",
    "print(f\"#col: {len(df.columns)}\")\n",
    "for col in numerical_cols:\n",
    "    n = len(df[col].unique())\n",
    "    if n > 7:\n",
    "        print(f\"{col}:{n}\")\n",
    "        bin_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer these bin cols to float\n",
    "for col in bin_cols:\n",
    "    try:\n",
    "        df[col] = df[col].astype(float)\n",
    "    except:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"' - 50000.'\" \"' 50000+.'\"]\n"
     ]
    }
   ],
   "source": [
    "print(df[41].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to 1,0\n",
    "map_y = {\"' - 50000.'\": 0, \"' 50000+.'\":1}\n",
    "df[41] = df[41].map(map_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS/ALL : 18568/299285\n"
     ]
    }
   ],
   "source": [
    "print(f\"POS/ALL : {sum(df[41].values)}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[41]\n",
    "del df[41]\n",
    "# X = df[range(69)]\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optbinning_data(df:pd.DataFrame, column:int, y:np.array):\n",
    "    x = df[column].values\n",
    "\n",
    "    optb = OptimalBinning(name=\"23\", dtype=\"numerical\", solver=\"cp\",\n",
    "                      monotonic_trend=\"auto\", \n",
    "                      max_n_prebins=100,\n",
    "                      min_prebin_size=0.001, time_limit=200)\n",
    "    optb.fit(x,y)\n",
    "    res = optb.transform(x, metric=\"indices\")\n",
    "    bin_number = max(res)\n",
    "    status = optb.status\n",
    "    set_n = len(df[column].unique())\n",
    "    print(f\"bin column:{column}, set size {set_n}, bin status {status}, bin_number {bin_number}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin column:0, set size 91, bin status OPTIMAL, bin_number 45\n",
      "bin column:2, set size 52, bin status OPTIMAL, bin_number 5\n",
      "bin column:3, set size 47, bin status OPTIMAL, bin_number 1\n",
      "bin column:5, set size 1425, bin status OPTIMAL, bin_number 5\n",
      "bin column:16, set size 133, bin status OPTIMAL, bin_number 6\n",
      "bin column:17, set size 114, bin status OPTIMAL, bin_number 6\n",
      "bin column:18, set size 1675, bin status OPTIMAL, bin_number 16\n",
      "bin column:24, set size 123232, bin status FEASIBLE, bin_number 10\n",
      "bin column:39, set size 53, bin status OPTIMAL, bin_number 18\n"
     ]
    }
   ],
   "source": [
    "for col in bin_cols:\n",
    "    v = optbinning_data(X, col, Y.values)\n",
    "    X[col] = v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "col_to_value2token = {}\n",
    "cnt = 0\n",
    "for col in X.columns:\n",
    "    col_values = X[col].values\n",
    "    col_to_value2token[col] = {}\n",
    "    col_values_set = set(col_values)\n",
    "    for val in col_values_set:\n",
    "        if val not in col_to_value2token[col]:\n",
    "            col_to_value2token[col][val] = cnt\n",
    "            cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace value with token\n",
    "for col in X.columns:\n",
    "    value_to_token = col_to_value2token[col]\n",
    "    X[col] = X[col].map(value_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_tmp, Y_train, Y_tmp = train_test_split(X,Y, test_size=0.2, random_state=2024)\n",
    "X_val, X_test,Y_val, Y_test = train_test_split(X_tmp, Y_tmp, test_size=0.5, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to libsvm\n",
    "def save_dataset(X, Y, file_path:str):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        n = len(X)\n",
    "        for i in range(n):\n",
    "            row = X.iloc[i].values \n",
    "            y = Y.iloc[i]\n",
    "            items =[str(y)] + [str(i)+\":1\" for i in row]\n",
    "            line = ' '.join(items) + '\\n'\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/hdd1/sams/data/census/train.libsvm'\n",
    "val_file = '/hdd1/sams/data/census/val.libsvm'\n",
    "test_file = '/hdd1/sams/data/census/test.libsvm'\n",
    "save_dataset(X_train, Y_train, train_file)\n",
    "save_dataset(X_val, Y_val, val_file)\n",
    "save_dataset(X_test, Y_test, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: POS/ALL -> 14804/239428\n",
      "val: POS/ALL -> 1835/29928\n",
      "test: POS/ALL -> 1929/29929\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: POS/ALL -> {sum(Y_train.values.reshape(-1))}/{len(Y_train)}\")\n",
    "print(f\"val: POS/ALL -> {sum(Y_val.values.reshape(-1))}/{len(Y_val)}\")\n",
    "print(f\"test: POS/ALL -> {sum(Y_test.values.reshape(-1))}/{len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns:41\n"
     ]
    }
   ],
   "source": [
    "print(f\"columns:{len(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
